<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
<title type="text">Avital Oliver</title>
<subtitle type="text">Tagline.</subtitle>
<generator uri="https://github.com/mojombo/jekyll">Jekyll</generator>
<link rel="self" type="application/atom+xml" href="http://localhost:4000/feed.xml" />
<link rel="alternate" type="text/html" href="http://localhost:4000" />
<updated>2018-05-29T19:31:01-07:00</updated>
<id>http://localhost:4000/</id>
<author>
  <name>Avital Oliver</name>
  <uri>http://localhost:4000/</uri>
  <email>avital@aoliver.org</email>
</author>


<entry>
  <title type="html"><![CDATA[Correcting a proof in the InfoGAN paper]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/correct-proof-of-infogan-lemma" />
  <id>http://localhost:4000/correct-proof-of-infogan-lemma</id>
  <published>2018-05-29T06:53:58-07:00</published>
  <updated>2018-05-29T06:53:58-07:00</updated>
  <author>
    <name>Avital Oliver</name>
    <uri>http://localhost:4000</uri>
    <email>avital@aoliver.org</email>
  </author>
  <content type="html">&lt;p&gt;The
&lt;a href=&quot;https://arxiv.org/pdf/1606.03657.pdf&quot;&gt;InfoGAN paper&lt;/a&gt;
has the following lemma:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lemma 5.1.&lt;/strong&gt;
For random variables &lt;script type=&quot;math/tex&quot;&gt;X, Y&lt;/script&gt; and function &lt;script type=&quot;math/tex&quot;&gt;f(x, y)&lt;/script&gt; under suitable regularity conditions:
&lt;script type=&quot;math/tex&quot;&gt;\mathbb{E}_{x \sim X, y \sim Y|x}[f(x, y)] = 
 \mathbb{E}_{x \sim X, y \sim Y|x, x' \sim X|y}[f(x', y)]&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The statement is correct, but the proof in the paper is confused – here’s a step where &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; mysteriously becomes &lt;script type=&quot;math/tex&quot;&gt;x'&lt;/script&gt;:&lt;/p&gt;

&lt;!--more--&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
&amp; \int_x \int_y P(x,y) {\color{red}{f(x,y)}} \int_{x'} P(x' | y)dx'dydx \\
= &amp; \int_x P(x) \int_y P(y|x) \int_{x'} P(x'|y) {\color{red}{f(x',y)}} dx' dy dx
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;After consulting with others, we weren’t able to fix that step of the proof. Instead, Nic Ford found this alternative proof. Hopefully this could help others reading the paper.&lt;/p&gt;

&lt;p&gt;Proof.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
   &amp; \mathbb{E}_{x \sim X,y \sim Y|x}[f(x, y)] = &amp; \mbox{make expectations explicit...} \\
   &amp; \mathbb{E}_{x \sim P(X)}\big[\mathbb{E}_{y \sim P(Y|X=x)}[f(x, y)]\big] = &amp; \mbox{by definition of $P(Y|X=x)$...} \\
   &amp; \mathbb{E}_{x,y \sim P(X,Y)}[f(x, y)] = &amp; \mbox{by definition of $P(X|Y=y)$... ...} \\
   &amp; \mathbb{E}_{y \sim P(Y)}\big[\mathbb{E}_{x \sim P(X|Y=y)}[f(x, y)]\big] = &amp; \mbox{rename $x$ to $x'$...} \\
   &amp; \mathbb{E}_{y \sim P(Y)}\big[\mathbb{E}_{x' \sim P(X|Y=y)}[f(x', y)]\big] = &amp; \mbox{by the law of total expectation...} \\
   &amp; \mathbb{E}_{x \sim P(X)}\Big[\mathbb{E}_{y \sim P(Y|X=x)}\big[\mathbb{E}_{x' \sim P(X|Y=y)}[f(x', y)]\big]\Big] = &amp;  \mbox{make expectations implicit...} \\
   &amp; \mathbb{E}_{x \sim X,y \sim Y|x,x' \sim X|y}[f(x', y)] &amp; \\
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;(This note is also available as a &lt;a href=&quot;/assets/correct-proof-of-infogan-lemma.pdf&quot;&gt;PDF&lt;/a&gt;.)&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;http://localhost:4000/correct-proof-of-infogan-lemma&quot;&gt;Correcting a proof in the InfoGAN paper&lt;/a&gt; was originally published by Avital Oliver at &lt;a href=&quot;http://localhost:4000&quot;&gt;Avital Oliver&lt;/a&gt; on May 29, 2018.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Why Mean Squared Error and L2 regularization? A probabilistic justification.]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/why-mse" />
  <id>http://localhost:4000/why-mse</id>
  <published>2017-03-20T11:27:31-07:00</published>
  <updated>2017-03-20T11:27:31-07:00</updated>
  <author>
    <name>Avital Oliver</name>
    <uri>http://localhost:4000</uri>
    <email>avital@aoliver.org</email>
  </author>
  <content type="html">&lt;p&gt;When you solve a regression problem with gradient descent, you’re
minimizing some differentiable loss function. The most commonly used
loss function is mean squared error (aka MSE, &lt;script type=&quot;math/tex&quot;&gt;\ell_2&lt;/script&gt; loss). Why? Here is a simple probabilistic justification, which can also be used to explain &lt;script type=&quot;math/tex&quot;&gt;\ell_1&lt;/script&gt; loss,
 as well as &lt;script type=&quot;math/tex&quot;&gt;\ell_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\ell_2&lt;/script&gt; regularization.&lt;/p&gt;

&lt;!--more--&gt;
&lt;p&gt;(This note is also available as a &lt;a href=&quot;/assets/why-mse.pdf&quot;&gt;PDF&lt;/a&gt;.)&lt;/p&gt;
&lt;h2 id=&quot;what-is-regression&quot;&gt;What is regression?&lt;/h2&gt;

&lt;p&gt;What is a regression problem? In simplest form, we have a dataset &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}=\{ (x_i \in \mathbb{R}^n, y_i \in \mathbb{R} ) \}&lt;/script&gt; and want a function &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; that approximately maps &lt;script type=&quot;math/tex&quot;&gt;x_i&lt;/script&gt; to &lt;script type=&quot;math/tex&quot;&gt;y_i&lt;/script&gt; without overfitting. We typically choose a function (from some family &lt;script type=&quot;math/tex&quot;&gt;\Theta&lt;/script&gt;) parametrized by &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;. A simple parametrization is &lt;script type=&quot;math/tex&quot;&gt;f_\theta:x \mapsto x \cdot \theta&lt;/script&gt; where &lt;script type=&quot;math/tex&quot;&gt;\theta \in \Theta = \mathbb{R}^n&lt;/script&gt; – this is linear regression. Neural networks are another kind of parametrization.&lt;/p&gt;

&lt;p&gt;Now we use some optimization scheme to find a function in that family that minimizes some loss function on our data. Which loss function should we use? People commonly use mean squared error (aka &lt;script type=&quot;math/tex&quot;&gt;\ell_2&lt;/script&gt; loss):
&lt;script type=&quot;math/tex&quot;&gt;\frac{1}{|\mathcal{D}|}\sum(y_i - f_\theta(x_i))^2&lt;/script&gt;. Why?&lt;/p&gt;

&lt;h2 id=&quot;two-assumptions-1-data-is-noisy-2-we-want-the-most-likely-model&quot;&gt;Two assumptions: (1) Data is noisy; (2) We want the most likely model&lt;/h2&gt;

&lt;p&gt;Let’s start with a few assumptions:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The data is generated by a function in our family, parametrized by &lt;script type=&quot;math/tex&quot;&gt;\theta_\text{true}&lt;/script&gt;, plus noise, which can be modeled by a zero-mean Gaussian random variable:
\begin{equation}
f_\text{data}(x) = f_{\theta_\text{true}}(x) + \epsilon
\end{equation}
\begin{equation}
\epsilon \sim \mathcal{N}(0, \sigma^2)
\end{equation}
(Why Gaussian? We’ll get back to this question later.)&lt;/li&gt;
  &lt;li&gt;Given the data, we’d like to find the most probable model within our family. Formally,
we’re looking for parameters &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; with the highest probability:
\begin{equation}
\operatorname*{arg\,max}_\theta(P(\theta \mid \mathcal{D}))
\end{equation}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;With these assumptions, we can derive &lt;script type=&quot;math/tex&quot;&gt;\ell_2&lt;/script&gt; loss as the principled error metric to optimize. Let’s see how.&lt;/p&gt;

&lt;h2 id=&quot;probability-of-data-given-parameters&quot;&gt;Probability of data given parameters&lt;/h2&gt;
&lt;p&gt;First, observe that with these two assumptions, we can derive the probability of a particular datapoint &lt;script type=&quot;math/tex&quot;&gt;(x, y)&lt;/script&gt;:&lt;/p&gt;

&lt;p&gt;\begin{align}
P((x, y) \in \mathcal{D} \mid \theta) &amp;amp; = 
P(y=f_\theta(x) + \epsilon \mid \epsilon \sim \mathcal{N}(0, \sigma^2)))   \\ &amp;amp; = \mathcal{N}(y - f_\theta(x); 0, \sigma^2) \\ &amp;amp; = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(y-f_\theta(x)^2}{2\sigma^2}}
\end{align}&lt;/p&gt;

&lt;p&gt;The math will be less complicated if we use log probability, so let’s switch to that here:&lt;/p&gt;

&lt;p&gt;\begin{align}
\log P((x, y) \in \mathcal{D} \mid \theta) &amp;amp; = 
\log \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(y-f_\theta(x)) ^2}{2\sigma^2}} \\ &amp;amp; = -\frac{(y-f_\theta(x)) ^2}{2\sigma^2} + const.
\end{align}&lt;/p&gt;

&lt;p&gt;Notice the &lt;script type=&quot;math/tex&quot;&gt;(y-f_\theta(x))^2&lt;/script&gt; term above – that’s how we’re going to get the &lt;script type=&quot;math/tex&quot;&gt;\ell_2&lt;/script&gt; loss. (Where did it come from? Could we have gotten something else there?)&lt;/p&gt;

&lt;p&gt;Now we can extend this from the log probability of a data point to the log probability of the entire dataset. This requires us to assume that each data point is independently sampled, commonly called the &lt;strong&gt;i.i.d. assumption&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;\begin{align}
\log P(\mathcal{D} \mid \theta) &amp;amp; = 
\sum \log P(y_i=f_\theta(x_i) + \epsilon \mid \epsilon \sim \mathcal{N}(0, \sigma^2))) \\ &amp;amp; = -\frac{1}{2\sigma^2} \sum_{x, y \in \mathcal{D}} (y - f_\theta(x))^2 + const.
\end{align}&lt;/p&gt;

&lt;p&gt;That’s a simple formula for the probability of our data given our parameters. However, what we really want is to maximize the probability of the parameters given the data, i.e. &lt;script type=&quot;math/tex&quot;&gt;P(\theta \mid \mathcal{D})&lt;/script&gt;.&lt;/p&gt;

&lt;h2 id=&quot;minimizing-mse-is-maximizing-probability&quot;&gt;Minimizing MSE &lt;strong&gt;is&lt;/strong&gt; maximizing probability&lt;/h2&gt;

&lt;p&gt;We turn to Bayes’ rule, &lt;script type=&quot;math/tex&quot;&gt;P(\theta \mid \mathcal{D}) \propto P(\mathcal{D} \mid \theta) P(\theta)&lt;/script&gt;, and find that:&lt;/p&gt;

&lt;p&gt;\begin{align}
    \log P(\theta \mid \mathcal{D}) &amp;amp; =  \log P(\mathcal{D} \mid \theta) + \log P(\theta) + const. \\     &amp;amp; = \left[ -\frac{1}{2\sigma^2} \sum_{x, y \in \mathcal{D}} (y - f_\theta(x))^2  \right] + \log P(\theta) + const.
\end{align}&lt;/p&gt;

&lt;p&gt;The term in the left-hand side logarithm, &lt;script type=&quot;math/tex&quot;&gt;P(\theta \mid \mathcal{D})&lt;/script&gt;, is called the &lt;strong&gt;posterior distribution&lt;/strong&gt;. The two non-constant right-hand side terms also have names: &lt;script type=&quot;math/tex&quot;&gt;P(\mathcal{D} \mid \theta)&lt;/script&gt; is the &lt;strong&gt;likelihood&lt;/strong&gt;, and &lt;script type=&quot;math/tex&quot;&gt;P(\theta)&lt;/script&gt; is the &lt;strong&gt;prior distribution&lt;/strong&gt; (the likelihood does not integrate to 1, so it’s not a distribution). The prior is a distribution we have to choose based on assumptions outside of our data. Let’s start with the simplest – the so-called &lt;strong&gt;uninformative prior&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;P(\theta) \propto 1&lt;/script&gt;, which doesn’t describe a real probability distribution but still lets us compute the posterior.
Choosing an uninformative prior corresponds to making no judgement about which parameters are more likely. If we choose the uninformative prior, we get:&lt;/p&gt;

&lt;p&gt;\begin{align}
   \log P(\theta \mid \mathcal{D}) &amp;amp; =  \log P(\mathcal{D} \mid \theta) + \log P(\theta) + const. \\    &amp;amp; = -\frac{1}{2\sigma^2} \sum_{x, y \in \mathcal{D}} (y - f_\theta(x))^2  + const.
\end{align}&lt;/p&gt;

&lt;p&gt;Ok woah. We’re there. Maximizing &lt;script type=&quot;math/tex&quot;&gt;P(\theta \mid \mathcal{D})&lt;/script&gt; is the same as minimizing &lt;script type=&quot;math/tex&quot;&gt;\sum (y_i - f_\theta(x_i))^2&lt;/script&gt;. The formal way of saying this is that minimizing mean squared error maximizes the &lt;strong&gt;likelihood&lt;/strong&gt; of the parameters. In short, we’ve found the &lt;strong&gt;maximum likelihood estimator&lt;/strong&gt; (MLE).&lt;/p&gt;

&lt;h2 id=&quot;if-we-change-our-assumptions-though&quot;&gt;If we change our assumptions, though…&lt;/h2&gt;

&lt;p&gt;We can also change our assumptions and see what happens:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;What if we change the variance on the noise? The log posterior which we’re maximizing changes by a constant factor, so the same model is most likely. We only needed to assume that the noise is drawn from &lt;strong&gt;some&lt;/strong&gt; zero-mean Gaussian. (The variance matters if we place a prior as in (3) below)&lt;/li&gt;
  &lt;li&gt;If we assume a different type of noise distribution, we’d derive a different loss function. For example, if we model the noise as being drawn from a Laplace distribution, we’d end up with &lt;script type=&quot;math/tex&quot;&gt;\ell_1&lt;/script&gt; error instead.&lt;/li&gt;
  &lt;li&gt;If we actually place a prior on our parameters we’d get a regularization term added to the log posterior that we’re maximizing. For example, if the prior is a zero-mean Gaussian, we’d get &lt;script type=&quot;math/tex&quot;&gt;\ell_2&lt;/script&gt; regularization. And if the prior is a zero-mean Laplacian, we’d get &lt;script type=&quot;math/tex&quot;&gt;\ell_1&lt;/script&gt; regularization. When we set a prior, we call the most likely parameters the &lt;strong&gt;maximum a posteriori estimate&lt;/strong&gt; (MAP).&lt;/li&gt;
  &lt;li&gt;What if our models have different types of parameters, such as the layers in a neural network? We would still want to place a prior on them to avoid overfitting, but we’d want a different prior for different layers. This corresponds to choosing different regularization hyperparameters for each layer.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;But don’t believe me – derive these yourself!&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;http://localhost:4000/why-mse&quot;&gt;Why Mean Squared Error and L2 regularization? A probabilistic justification.&lt;/a&gt; was originally published by Avital Oliver at &lt;a href=&quot;http://localhost:4000&quot;&gt;Avital Oliver&lt;/a&gt; on March 20, 2017.&lt;/p&gt;</content>
</entry>

</feed>